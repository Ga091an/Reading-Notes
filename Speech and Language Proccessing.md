# Speech and Language Processing
> Book: Daniel Jurafsky and James H. Martin. Speech and Language Processing An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition. Third Edition draft, online.
> and the draft of the second version

## Introduction
text normalization: 将语言转化成一个更规整的格式。
tokenization: 即分词。
lemmatization：将一个单词/token的不同形态统一。
stemming：是lemmatization的一种简单形式，即去除单词后缀。
sentence segmentation：将文本按句切分。
edit distance：描述句子/单词之间不同程度的度量，the number of edits (insertions, deletions, substitutions) it takes to change one string into the other.

## Charpter 2 Reguar experssion, text normalization, edit distance
> the new version

__Normalizing text__: Convert it to a  more convenient, stand form. Text normalization is a set of tasks collectively.  
__Tokenization__: Segmente runing text into words  
__normalization__: Put words/tokens in a standard format.  
__Lemmatization__: The task of determining that two words have the same root, despite their surface differences.  
__Stemming__: a simpler version of lemmatization, which just strips suffixes from the end of the word.  
__Sentence segmentation__: Break text into individual sentences.

## Charpter 3 words & transducer
> the second version

__Parsing__: taking an input and producing some sort of Linguistic structure for it.  
__Productive suffix__: it applies to very verb.  
__Morphology__: the study of the way words are built up from smaller meaning-bearing units, *morphems*（defined as the minimun meaning-bearing unit in a language, more specifically, like *stems* or *affixes*）.
